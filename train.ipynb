{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1406,
     "status": "ok",
     "timestamp": 1680546922536,
     "user": {
      "displayName": "Yuxiao Liu",
      "userId": "00349421896740538734"
     },
     "user_tz": 240
    },
    "id": "QQsK0kcjOK8F",
    "outputId": "70cf75e3-fc67-42d0-cc54-a2ac046bcd50"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd /content/gdrive/MyDrive/si699-music-tagging/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6UgeAtwKJ8Q"
   },
   "outputs": [],
   "source": [
    "# %%python3 preprocessing/convert_npy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gB3UgwVXJoY4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyuxiao/.local/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/lyuxiao/.local/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator12recordStreamERKNS_7DataPtrENS0_10CUDAStreamE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run on: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import glob\n",
    "import torchaudio\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import csv\n",
    "from transformers import AutoConfig, AutoFeatureExtractor, Wav2Vec2FeatureExtractor\n",
    "from sklearn.metrics import *\n",
    "from run.models import *\n",
    "import collections\n",
    "import torch\n",
    "import yaml\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertModel, BertTokenizer\n",
    "# from transformers import ASTForAudioClassification, Wav2Vec2Processor, AutoConfig\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import (\n",
    "    Wav2Vec2PreTrainedModel,\n",
    "    Wav2Vec2Model\n",
    ")\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics.functional.classification import multilabel_auroc\n",
    "from torchmetrics.classification import MultilabelPrecision\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "torch.manual_seed(config['seed'])\n",
    "random.seed(config['seed'])\n",
    "print(\"Run on:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6465,
     "status": "ok",
     "timestamp": 1680546932702,
     "user": {
      "displayName": "Yuxiao Liu",
      "userId": "00349421896740538734"
     },
     "user_tz": 240
    },
    "id": "lrWxObbsPRG-",
    "outputId": "1ef1171a-b975-4490-c24d-6118f2ea9b54"
   },
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tracks_dict, npy_root, config, tags, data_type, feature_extractor_type):\n",
    "        self.npy_root = npy_root\n",
    "        self.config = config\n",
    "        self.tracks_dict = tracks_dict\n",
    "        self.tags = tags\n",
    "        self.mlb = LabelBinarizer().fit(self.tags)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.title_dict = {}\n",
    "        self.prepare_title()\n",
    "        self.data = []\n",
    "        self.input_ids = []\n",
    "        self.attention_mask = []\n",
    "        self.labels = []\n",
    "        self.data_type = data_type\n",
    "        self.prepare_data()\n",
    "        self.feature_extractor_type = feature_extractor_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert 0 <= index < len(self)\n",
    "        waveform = self.data[index]\n",
    "        input_ids = self.input_ids[index]\n",
    "        attention_mask = self.attention_mask[index]\n",
    "        target = self.labels[index]\n",
    "        if self.feature_extractor_type == 'raw':\n",
    "            mel_spec = torch.Tensor(waveform)\n",
    "        if self.feature_extractor_type == 'ast':\n",
    "            feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "                \"MIT/ast-finetuned-audioset-10-10-0.4593\",\n",
    "                sampling_rate=self.config['sample_rate'],\n",
    "                num_mel_bins=self.config['n_mels']\n",
    "            )\n",
    "            encoding = feature_extractor(waveform, sampling_rate=self.config['sample_rate'], annotations=target, return_tensors=\"pt\")\n",
    "            mel_spec = encoding['input_values'].squeeze()\n",
    "            mel_spec = torch.transpose(mel_spec, 0, 1)\n",
    "        if self.feature_extractor_type == 'wav2vec':\n",
    "            feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\n",
    "                \"facebook/wav2vec2-base-960h\"\n",
    "            )\n",
    "            encoding = feature_extractor(waveform, sampling_rate=self.config['sample_rate'],\n",
    "                                         return_tensors=\"pt\")\n",
    "            mel_spec = encoding['input_values'].squeeze()\n",
    "        return mel_spec, input_ids, attention_mask, target\n",
    "    \n",
    "    def prepare_title(self):\n",
    "        whole_filenames = sorted(glob.glob(os.path.join(self.npy_root, \"*/*.npy\")))\n",
    "        titles = []\n",
    "        for filename in whole_filenames:\n",
    "            file_id = os.path.join(filename.split('/')[-2], filename.split('/')[-1].split('.')[0])\n",
    "            titles.append(self.tracks_dict[file_id][1])\n",
    "        encoding = self.tokenizer(titles, return_tensors='pt', padding=True, truncation=True)\n",
    "        input_ids = encoding['input_ids']\n",
    "        attention_mask = encoding['attention_mask']\n",
    "        for idx, filename in enumerate(whole_filenames):\n",
    "            file_id = os.path.join(filename.split('/')[-2], filename.split('/')[-1].split('.')[0])\n",
    "            self.title_dict[file_id] = (input_ids[idx], attention_mask[idx])\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        whole_filenames = sorted(glob.glob(os.path.join(self.npy_root, \"*/*.npy\")))\n",
    "        train_size = int(len(whole_filenames) * 0.8)\n",
    "        filenames = []\n",
    "        random.shuffle(whole_filenames)\n",
    "        if self.data_type == 'train':\n",
    "            filenames = whole_filenames[:train_size]\n",
    "        if self.data_type == 'valid':\n",
    "            filenames = whole_filenames[train_size:]\n",
    "        for filename in tqdm(filenames):\n",
    "            file_id = os.path.join(filename.split('/')[-2], filename.split('/')[-1].split('.')[0])\n",
    "            if file_id not in self.tracks_dict:\n",
    "                print(file_id)\n",
    "                continue\n",
    "            self.data.append(np.load(filename))\n",
    "            self.input_ids.append(self.title_dict[file_id][0])\n",
    "            self.attention_mask.append(self.title_dict[file_id][1])\n",
    "            self.labels.append(np.sum(self.mlb.transform(self.tracks_dict[file_id][0]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(tag_file, npy_root, isMap):\n",
    "    id2title_dict = {}\n",
    "    with open('data/raw.meta.tsv') as fp:\n",
    "        reader = csv.reader(fp, delimiter='\\t')\n",
    "        next(reader, None)\n",
    "        for row in reader:\n",
    "            id2title_dict[row[0]] = row[3]\n",
    "\n",
    "    if isMap:\n",
    "        f = open('tag_categorize.json')\n",
    "        data = json.load(f)\n",
    "        categorize = {}\n",
    "        for k, v in data.items():\n",
    "            for i in v[1:-1].split(', '):\n",
    "                categorize[i] = k\n",
    "    tracks = {}\n",
    "    total_tags = []\n",
    "    with open(tag_file) as fp:\n",
    "        reader = csv.reader(fp, delimiter='\\t')\n",
    "        next(reader, None)  # skip header\n",
    "        for row in reader:\n",
    "            if not os.path.exists(os.path.join(npy_root, row[3].replace('.mp3', '.npy'))):\n",
    "                print(os.path.join(npy_root, row[3].replace('.mp3', '.npy')))\n",
    "                continue\n",
    "            track_id = row[3].split('.')[0]\n",
    "            tags = []\n",
    "            for tag in row[5:]:\n",
    "                if isMap:\n",
    "                    tags.append(categorize[tag.split('---')[-1]])\n",
    "                else:\n",
    "                    tags.append(tag.split('---')[-1])\n",
    "            tracks[track_id] = (list(set(tags)), id2title_dict[row[0]])\n",
    "            total_tags += list(set(tags))\n",
    "    print(\"Distribution of tags:\", collections.Counter(total_tags))\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.hist(total_tags)\n",
    "    plt.savefig('dist.png')\n",
    "    return tracks, list(set(total_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n",
      "Distribution of tags: Counter({'happy': 1657, 'film': 1502, 'energetic': 1357, 'relaxing': 1350, 'emotional': 1271, 'melodic': 1213, 'dark': 1202, 'epic': 982, 'dream': 951, 'love': 909, 'inspiring': 877, 'sad': 749, 'meditative': 742, 'uplifting': 693, 'advertising': 673, 'deep': 635, 'motivational': 635, 'romantic': 627, 'christmas': 623, 'documentary': 612, 'corporate': 609, 'positive': 539, 'summer': 505, 'space': 503, 'background': 496, 'soundscape': 480, 'fun': 480, 'soft': 465, 'ambiental': 460, 'calm': 457, 'children': 456, 'adventure': 448, 'upbeat': 444, 'melancholic': 441, 'slow': 437, 'commercial': 428, 'drama': 424, 'movie': 413, 'action': 407, 'ballad': 334, 'dramatic': 317, 'sport': 297, 'trailer': 270, 'party': 266, 'game': 261, 'nature': 259, 'cool': 251, 'powerful': 238, 'hopeful': 216, 'retro': 213, 'funny': 203, 'groovy': 194, 'holiday': 176, 'travel': 171, 'horror': 158, 'heavy': 156, 'mellow': 154, 'sexy': 122, 'fast': 119})\n",
      "59\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "tag_file = 'data/autotagging_moodtheme.tsv'\n",
    "npy_root = 'data/waveform'\n",
    "tracks_dict, tags = get_tags(tag_file, npy_root, False)\n",
    "N_CLASSES = len(tags)\n",
    "print(N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14788/14788 [07:00<00:00, 35.16it/s]\n",
      "100%|██████████| 3698/3698 [00:23<00:00, 160.30it/s]\n"
     ]
    }
   ],
   "source": [
    "transform = 'raw'\n",
    "batch_size = 4\n",
    "train_dataset = MyDataset(tracks_dict, npy_root, config, tags, \"train\", transform)\n",
    "val_dataset = MyDataset(tracks_dict, npy_root, config, tags, \"valid\", transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2647, -0.1546, -0.0190,  ...,  0.0558, -0.7055,  0.2956],\n",
      "        [-0.0667,  0.2654,  0.1454,  ...,  0.1265, -0.0362, -0.0065],\n",
      "        [-0.0720, -0.0663,  0.0706,  ..., -0.5072, -0.0366,  0.1323],\n",
      "        [ 0.1688, -0.2995, -0.1785,  ...,  0.3414, -0.2259, -0.1064]])\n",
      "tensor([[  101,  7484, 21262,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5292,  1043, 19291,  2290,  1011,   100,  1770,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2064,  1005,  1056, 11997,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3931, 18158,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "for waveform, input_ids, attention_mask, label in val_loader:\n",
    "    print(waveform)\n",
    "    print(input_ids)\n",
    "    print(attention_mask)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GfVtoBLpK7Us"
   },
   "outputs": [],
   "source": [
    "def train(model, epoch, criterion, optimizer, train_loader, is_title=False):\n",
    "    losses = []\n",
    "    ground_truth = []\n",
    "    prediction = []\n",
    "    model.train()\n",
    "    for waveform, input_ids, attention_mask, label in tqdm(train_loader):\n",
    "        waveform, label = waveform.to(device), label.to(device)\n",
    "        input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "        if is_title:\n",
    "            output = model(waveform, input_ids, attention_mask)\n",
    "        else:\n",
    "            output = model(waveform)\n",
    "        loss = criterion(output, label.float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.cpu().detach())\n",
    "        ground_truth.append(label)\n",
    "        prediction.append(output)\n",
    "    get_eval_metrics(prediction, ground_truth, 'train', epoch, losses)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, epoch, criterion, val_loader, is_title=False):\n",
    "    losses = []\n",
    "    ground_truth = []\n",
    "    prediction = []\n",
    "    model.eval()\n",
    "    for waveform, input_ids, attention_mask, label in tqdm(val_loader):\n",
    "        waveform, label = waveform.to(device), label.to(device)\n",
    "        input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "        if is_title:\n",
    "            output = model(waveform, input_ids, attention_mask)\n",
    "        else:\n",
    "            output = model(waveform)\n",
    "        loss = criterion(output, label.float())\n",
    "        losses.append(loss.cpu().detach())\n",
    "        ground_truth.append(label)\n",
    "        prediction.append(output)\n",
    "    pre = get_eval_metrics(prediction, ground_truth, 'val', epoch, losses)\n",
    "    return pre\n",
    "\n",
    "\n",
    "def get_eval_metrics(outputs, labels, run_type, epoch, losses):\n",
    "    outputs = torch.cat(outputs, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    assert outputs.shape == labels.shape\n",
    "    # 1. number of correctly predicted tags divided by the total number of tags\n",
    "    prob_classes = []\n",
    "    for i in range(labels.size(0)):\n",
    "        label = labels[i]\n",
    "        k = label.sum()\n",
    "        _, idx = outputs[i].topk(k=k)\n",
    "        predict = torch.zeros_like(outputs[i])\n",
    "        predict[idx] = 1\n",
    "        prob_classes.append(predict)\n",
    "    prob_classes = torch.stack(prob_classes)\n",
    "    matched_1s = torch.mul(prob_classes, labels)\n",
    "    correct_tag_percentage = matched_1s.sum() / labels.sum()\n",
    "\n",
    "    # 2. Auroc\n",
    "    auroc = multilabel_auroc(outputs, labels, num_labels=N_CLASSES, average=\"macro\", thresholds=None).item()\n",
    "\n",
    "    # 3. avg precision\n",
    "    metric = MultilabelPrecision(average='macro', num_labels=N_CLASSES, thresholds=None).to(device)\n",
    "    pre = metric(outputs, labels).item()\n",
    "\n",
    "    # write tensorboard and logging file\n",
    "    writer.add_scalar(\"Loss/{}\".format(run_type), np.mean(losses), epoch)\n",
    "    writer.add_scalar(\"Auroc/{}\".format(run_type), auroc, epoch)\n",
    "    writer.add_scalar(\"Pre/{}\".format(run_type), pre, epoch)\n",
    "    writer.add_scalar(\"Avg_percent/{}\".format(run_type), correct_tag_percentage, epoch)\n",
    "    print(\"{} - epoch: {}, loss: {}, auroc: {}, pre: {}, avg percent: {}\".format(\n",
    "        run_type, epoch, np.mean(losses), auroc, pre, correct_tag_percentage))\n",
    "    logging.info(\"{} - epoch: {}, loss: {}, auroc: {}, pre: {}, avg percent: {}\".format(\n",
    "        run_type, epoch, np.mean(losses), auroc, pre, correct_tag_percentage))\n",
    "    return correct_tag_percentage\n",
    "\n",
    "\n",
    "def get_model(model_name, tags):\n",
    "    if model_name =='samplecnn':\n",
    "        model = SampleCNN(N_CLASSES, config).to(device)\n",
    "    elif model_name == 'crnn':\n",
    "        model = CRNN(N_CLASSES, config).to(device)\n",
    "    elif model_name =='fcn':\n",
    "        model = FCN(N_CLASSES, config).to(device)\n",
    "    elif model_name == 'musicnn':\n",
    "        model = Musicnn(N_CLASSES, config).to(device)\n",
    "    elif model_name == 'musicnn_title':\n",
    "        model = MusicnnwithTitle(N_CLASSES, config).to(device)\n",
    "    elif model_name == 'shortchunkcnn_res':\n",
    "        model = ShortChunkCNN_Res(N_CLASSES, config).to(device)\n",
    "    elif model_name == 'cnnsa':\n",
    "        model = CNNSA(N_CLASSES, config).to(device)\n",
    "    elif model_name == 'baseline2':\n",
    "        model = Baseline2(N_CLASSES, config).to(device)\n",
    "    elif model_name == 'wav2vec':\n",
    "        model_config = AutoConfig.from_pretrained(\n",
    "            \"facebook/wav2vec2-base-960h\",\n",
    "            num_labels=N_CLASSES,\n",
    "            label2id={label: i for i, label in enumerate(tags)},\n",
    "            id2label={i: label for i, label in enumerate(tags)},\n",
    "            finetuning_task=\"wav2vec2_clf\",\n",
    "        )\n",
    "        model = Wav2Vec2ForSpeechClassification(model_config).to(device)\n",
    "    else:\n",
    "        model = SampleCNN(N_CLASSES, config).to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicnnwithTitle(nn.Module):\n",
    "    def __init__(self, num_classes, config=None):\n",
    "        super(Musicnn, self).__init__()\n",
    "        self.spec = torchaudio.transforms.MelSpectrogram(sample_rate=config['sample_rate'],\n",
    "                                                  n_fft=config['n_fft'],\n",
    "                                                  f_min=config['fmin'],\n",
    "                                                  f_max=config['fmax'],\n",
    "                                                  n_mels=config['n_mels'])\n",
    "\n",
    "        # Spectrogram\n",
    "        self.to_db = torchaudio.transforms.AmplitudeToDB()\n",
    "        self.spec_bn = nn.BatchNorm2d(1)\n",
    "\n",
    "        # Pons front-end\n",
    "        m1 = Conv_V(1, 204, (int(0.7 * 96), 7))\n",
    "        m2 = Conv_V(1, 204, (int(0.4 * 96), 7))\n",
    "        m3 = Conv_H(1, 51, 129)\n",
    "        m4 = Conv_H(1, 51, 65)\n",
    "        m5 = Conv_H(1, 51, 33)\n",
    "        self.layers = nn.ModuleList([m1, m2, m3, m4, m5])\n",
    "\n",
    "        # Pons back-end\n",
    "        backend_channel = 512\n",
    "        self.layer1 = Conv_1d(561, backend_channel, kernel_size=7, stride=1, padding=3, pooling=1)\n",
    "        self.layer2 = Conv_1d(backend_channel, backend_channel, kernel_size=7, stride=1, padding=3, pooling=1)\n",
    "        self.layer3 = Conv_1d(backend_channel, backend_channel, kernel_size=7, stride=1, padding=3, pooling=1)\n",
    "\n",
    "        # Dense\n",
    "        dense_channel = 500\n",
    "        self.dense1 = nn.Linear((561 + (backend_channel * 3)) * 2, dense_channel)\n",
    "        self.bn = nn.BatchNorm1d(dense_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.Linear(dense_channel, num_classes)\n",
    "        \n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "        self.dense3 = nn.Linear(self.bert.config.hidden_size, 256)\n",
    "        self.dense4 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        self.dense5 = nn.Linear(2*num_classes, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x, input_ids=None, attention_mask=None):\n",
    "        # Spectrogram\n",
    "        x = self.spec(x)\n",
    "        x = self.to_db(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.spec_bn(x)\n",
    "\n",
    "        # Pons front-end\n",
    "        out = []\n",
    "        for layer in self.layers:\n",
    "            out.append(layer(x))\n",
    "        out = torch.cat(out, dim=1)\n",
    "\n",
    "        # Pons back-end\n",
    "        length = out.size(2)\n",
    "        res1 = self.layer1(out)\n",
    "        res2 = self.layer2(res1) + res1\n",
    "        res3 = self.layer3(res2) + res2\n",
    "        out = torch.cat([out, res1, res2, res3], 1)\n",
    "\n",
    "        mp = nn.MaxPool1d(length)(out)\n",
    "        avgp = nn.AvgPool1d(length)(out)\n",
    "\n",
    "        out = torch.cat([mp, avgp], dim=1)\n",
    "        out = out.squeeze(2)\n",
    "\n",
    "        out = self.relu(self.bn(self.dense1(out)))\n",
    "        out = self.dropout(out)\n",
    "        out = self.dense2(out)\n",
    "        \n",
    "        out_title = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        out_title = self.dense3(out_title.pooler_output)\n",
    "        out_title = self.dropout(out_title)\n",
    "        out_title = self.dense4(out_title)\n",
    "        \n",
    "        out = torch.cat((out_title, out), dim=1)\n",
    "        out = self.dense5(out)\n",
    "        out = nn.Sigmoid()(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107097,
     "status": "ok",
     "timestamp": 1680549293386,
     "user": {
      "displayName": "Yuxiao Liu",
      "userId": "00349421896740538734"
     },
     "user_tz": 240
    },
    "id": "b8HVJCWOT9GP",
    "outputId": "456e25f9-da20-42cc-f539-6184a0204f1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyuxiao/.local/lib/python3.9/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (257) may be set too low.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3697/3697 [07:39<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - epoch: 0, loss: 0.07646988332271576, auroc: 0.9861521124839783, pre: 0.8669588565826416, avg percent: 0.8885020613670349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [00:33<00:00, 27.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val - epoch: 0, loss: 0.25514987111091614, auroc: 0.8951526880264282, pre: 0.6540236473083496, avg percent: 0.673331081867218\n",
      "Best avg precision: tensor(0.6733, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3697/3697 [06:58<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - epoch: 1, loss: 0.06391412019729614, auroc: 0.9908768534660339, pre: 0.8906944990158081, avg percent: 0.9169921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [00:34<00:00, 27.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val - epoch: 1, loss: 0.2741473615169525, auroc: 0.8943119049072266, pre: 0.689926266670227, avg percent: 0.668078601360321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3697/3697 [07:00<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - epoch: 2, loss: 0.06071602925658226, auroc: 0.9917463064193726, pre: 0.9000226259231567, avg percent: 0.92357337474823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [00:34<00:00, 27.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val - epoch: 2, loss: 0.27402856945991516, auroc: 0.8970816135406494, pre: 0.677152156829834, avg percent: 0.6685869097709656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3697/3697 [06:40<00:00,  9.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - epoch: 3, loss: 0.05837182328104973, auroc: 0.9925333857536316, pre: 0.9025216102600098, avg percent: 0.9270550012588501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [00:32<00:00, 28.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val - epoch: 3, loss: 0.27218177914619446, auroc: 0.8983380198478699, pre: 0.6699137687683105, avg percent: 0.6785835027694702\n",
      "Best avg precision: tensor(0.6786, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3697/3697 [06:39<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - epoch: 4, loss: 0.05657251551747322, auroc: 0.9929123520851135, pre: 0.9063295125961304, avg percent: 0.93215012550354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [00:32<00:00, 28.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val - epoch: 4, loss: 0.26015374064445496, auroc: 0.9006295204162598, pre: 0.6780236959457397, avg percent: 0.691629946231842\n",
      "Best avg precision: tensor(0.6916, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3697/3697 [06:38<00:00,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - epoch: 5, loss: 0.056826744228601456, auroc: 0.9928158521652222, pre: 0.904435396194458, avg percent: 0.93019700050354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [00:32<00:00, 28.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val - epoch: 5, loss: 0.27713048458099365, auroc: 0.9002503752708435, pre: 0.6623246073722839, avg percent: 0.672653317451477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3697/3697 [06:39<00:00,  9.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - epoch: 6, loss: 0.05515450984239578, auroc: 0.9932425022125244, pre: 0.9089646339416504, avg percent: 0.9345703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [00:32<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val - epoch: 6, loss: 0.27062129974365234, auroc: 0.899032711982727, pre: 0.6762994527816772, avg percent: 0.6928160190582275\n",
      "Best avg precision: tensor(0.6928, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3697/3697 [06:38<00:00,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - epoch: 7, loss: 0.0534624420106411, auroc: 0.9937862753868103, pre: 0.911787748336792, avg percent: 0.93898606300354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [00:32<00:00, 28.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val - epoch: 7, loss: 0.2738068699836731, auroc: 0.902097761631012, pre: 0.6846397519111633, avg percent: 0.6809555888175964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3697/3697 [06:39<00:00,  9.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - epoch: 8, loss: 0.05278297886252403, auroc: 0.9939206838607788, pre: 0.912427544593811, avg percent: 0.93800950050354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [00:32<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val - epoch: 8, loss: 0.2737002670764923, auroc: 0.901712954044342, pre: 0.6894341707229614, avg percent: 0.6858692169189453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 64/3697 [00:07<06:41,  9.06it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2298314/4043893902.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbest_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpre\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_pre\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2298314/872137636.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epoch, criterion, optimizer, train_loader)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mground_truth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = 'musicnn_title'\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 10\n",
    "model = get_model(model_name, tags)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "print(\"Training and validating model...\")\n",
    "writer = SummaryWriter('runs/{}_{}_{}_{}'.format(model_name, learning_rate, batch_size, len(tags)))\n",
    "logging.basicConfig(filename=\"log/log_{}_{}_{}_{}\".format(model_name, learning_rate, batch_size, len(tags)),\n",
    "                    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "best_pre = float('-inf')\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, epoch, criterion, optimizer, train_loader, True)\n",
    "    pre = validate(model, epoch, criterion, val_loader, True)\n",
    "    if pre > best_pre:\n",
    "        print(\"Best avg precision:\", pre)\n",
    "        best_pre = pre\n",
    "        torch.save(model.state_dict(), 'model/{}_best_score_{}_{}.pt'.format(model_name, learning_rate, len(tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'happy': 1340, 'film': 1199, 'relaxing': 1091, 'energetic': 1055, 'emotional': 1035, 'melodic': 965, 'dark': 957, 'epic': 799, 'dream': 750, 'love': 736, 'inspiring': 710, 'sad': 611, 'meditative': 598, 'uplifting': 558, 'advertising': 557, 'deep': 532, 'motivational': 512, 'romantic': 504, 'christmas': 500, 'documentary': 486, 'corporate': 482, 'positive': 422, 'summer': 414, 'space': 406, 'background': 388, 'soundscape': 388, 'soft': 371, 'calm': 369, 'children': 367, 'adventure': 366, 'fun': 366, 'upbeat': 361, 'ambiental': 361, 'melancholic': 358, 'drama': 346, 'slow': 345, 'commercial': 344, 'movie': 329, 'action': 325, 'ballad': 258, 'dramatic': 257, 'sport': 237, 'trailer': 223, 'party': 222, 'nature': 216, 'game': 215, 'cool': 202, 'powerful': 189, 'groovy': 167, 'hopeful': 165, 'funny': 162, 'retro': 161, 'holiday': 140, 'travel': 131, 'mellow': 125, 'horror': 121, 'heavy': 113, 'sexy': 97, 'fast': 92})\n",
      "torch.Size([3698, 59])\n",
      "auroc: 0.5, pre: 0.0, avg percent: 0.04998471587896347\n"
     ]
    }
   ],
   "source": [
    "def baseline1(tag_file, npy_root, batch_size, isMap, val_loader, tags):\n",
    "    whole_filenames = sorted(glob.glob(os.path.join(npy_root, \"*/*.npy\")))\n",
    "    train_size = int(len(whole_filenames) * 0.8)\n",
    "    # val_size = int(len(whole_filenames) * 0.95)\n",
    "    filenames = []\n",
    "    random.shuffle(whole_filenames)\n",
    "    train_filenames = whole_filenames[:train_size]\n",
    "    train_ids = []\n",
    "    for filename in train_filenames:\n",
    "        train_ids.append(filename.split('/')[-2] + '/' + filename.split('/')[-1])\n",
    "    if isMap:\n",
    "        f = open('tag_categorize.json')\n",
    "        data = json.load(f)\n",
    "        categorize = {}\n",
    "        for k, v in data.items():\n",
    "            for i in v[1:-1].split(', '):\n",
    "                categorize[i] = k\n",
    "    train_total_tags = []\n",
    "    with open(tag_file) as fp:\n",
    "        reader = csv.reader(fp, delimiter='\\t')\n",
    "        next(reader, None)  # skip header\n",
    "        for row in reader:\n",
    "            if row[3].replace('.mp3', '.npy') not in train_ids:\n",
    "                # if not in train set\n",
    "                continue\n",
    "            if not os.path.exists(os.path.join(npy_root, row[3].replace('.mp3', '.npy'))):\n",
    "                print(os.path.join(npy_root, row[3].replace('.mp3', '.npy')))\n",
    "                continue\n",
    "            tmp = []\n",
    "            for tag in row[5:]:\n",
    "                if isMap:\n",
    "                    tmp.append(categorize[tag.split('---')[-1]])\n",
    "                else:\n",
    "                    tmp.append(tag.split('---')[-1])\n",
    "            train_total_tags += list(set(tmp))\n",
    "\n",
    "    train_dist_tags = collections.Counter(train_total_tags)\n",
    "    print(train_dist_tags)\n",
    "    total = 0\n",
    "    for v in train_dist_tags.values():\n",
    "        total += v\n",
    "    probs = []\n",
    "    for t in tags:\n",
    "        probs.append(train_dist_tags[t]/total)\n",
    "    labels, outputs = [], []\n",
    "    for _, _, _, label in val_loader:  \n",
    "        labels.append(label)\n",
    "        for _ in range(label.size(0)):\n",
    "            outputs.append(probs)\n",
    "    \n",
    "    outputs = torch.Tensor(outputs)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    print(outputs.shape)\n",
    "    assert outputs.shape == labels.shape, \"{}, {}\".format(outputs.shape, labels.shape)\n",
    "    # 1. number of correctly predicted tags divided by the total number of tags\n",
    "    prob_classes = []\n",
    "    for i in range(labels.size(0)):\n",
    "        label = labels[i]\n",
    "        k = label.sum()\n",
    "        _, idx = outputs[i].topk(k=k)\n",
    "        predict = torch.zeros_like(outputs[i])\n",
    "        predict[idx] = 1\n",
    "        # print(k, predict)\n",
    "        prob_classes.append(predict)\n",
    "    prob_classes = torch.stack(prob_classes)\n",
    "    matched_1s = torch.mul(prob_classes, labels)\n",
    "    correct_tag_percentage = matched_1s.sum() / labels.sum()\n",
    "\n",
    "    # 2. Auroc\n",
    "    auroc = multilabel_auroc(outputs, labels, num_labels=N_CLASSES, average=\"macro\", thresholds=None).item()\n",
    "\n",
    "    # 3. avg precision\n",
    "    metric = MultilabelPrecision(average='macro', num_labels=N_CLASSES, thresholds=None).to(device)\n",
    "    pre = metric(outputs, labels).item()\n",
    "\n",
    "    print(\"auroc: {}, pre: {}, avg percent: {}\".format(auroc, pre, correct_tag_percentage))\n",
    "baseline1(tag_file, npy_root, batch_size, False, val_loader, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
